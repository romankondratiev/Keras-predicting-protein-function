{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "np.random.seed(1337) \n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model #for functional API\n",
    "from keras.layers import Dense, Activation, Flatten, MaxPooling2D, Dropout, Input\n",
    "from keras.layers import Conv2D #layer that makes our CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # 32 data points trained with model at 1 epoch\n",
    "num_classes = 10 \n",
    "epochs = 5 #how many times NN will see our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data() #already splited\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 #normalize\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape) #50000 data points, each is 32*32*3 matrix, RGB \n",
    "print(x_train.shape[0], 'train samples') \n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes) #convert labels into binary\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() #load model\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), padding='same', #first class Conv2D, 16 filters, each 3 by 3 matrix\n",
    "                 input_shape=x_train.shape[1:])) #shape of input (without shape[0] which is number of our data points)\n",
    "model.add(Activation('relu')) # add activation function \n",
    "\n",
    "model.add(Conv2D(8, (3, 3))) #another Conv2D layer, input_shape argument is not needed anymore\n",
    "model.add(Activation('relu')) \n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2,2))) # max pooling, split our value in 2*2 matrix, and get max(values in this pool) / Improve accuracy a little bit\n",
    "\n",
    "model.add(Dropout(0.2)) #20% of pixels coming from the prev.layer will be dropped out\n",
    "#This way the NN could generalize more and learn more efficient without even see the whole picture\n",
    "\n",
    "model.add(Flatten()) #flatten! squize into 1-dim vector because dense layer needs something in 1 dimension\n",
    "model.add(Dense(num_classes)) # need to add this one, to have our number of classes!! but works only with one dim, so added flattn\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6) #optimizer\n",
    "\n",
    "# Let's train the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist1 = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# и все ;)  Натренировали и забили хуй"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist1.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(32, 32, 3))\n",
    "\n",
    "x = Conv2D(16, (3, 3), padding='same')(inputs) \n",
    "x = Activation('relu')(x) \n",
    "\n",
    "x = Conv2D(8, (3, 3))(x) \n",
    "x = Activation('relu')(x) \n",
    "x = MaxPooling2D(pool_size=(2, 2))(x) \n",
    "x = Flatten()(x) \n",
    "\n",
    "x = Dense(num_classes)(x) \n",
    "\n",
    "output = Activation('softmax')(x) \n",
    "\n",
    "model = Model([inputs], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "hist2 = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist2.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception Module / Graph model / Goggle Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input layer is the same as our typical CNN model \n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "\n",
    "## ----------- New Stuff Starts Here --------- \n",
    "\n",
    "\n",
    "tower_1 = Conv2D(64, (1, 1), padding='same', activation='relu')(inputs) #tower like on the picture in my notes\n",
    "#64 filter 1 by 1 each\n",
    "# we pass inputs to this tower\n",
    "\n",
    "tower_1 = Conv2D(64, (3, 3), padding='same', activation='relu', name='t1_conv')(tower_1)\n",
    "\n",
    "tower_2 = Conv2D(64, (1, 1), padding='same', activation='relu')(inputs)\n",
    "tower_2 = Conv2D(64, (5, 5), padding='same', activation='relu')(tower_2)\n",
    "\n",
    "tower_3 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(inputs)\n",
    "tower_3 = Conv2D(64, (1, 1), padding='same', activation='relu')(tower_3)\n",
    "\n",
    "\n",
    "x = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=1)  #filter concatenation\n",
    "\n",
    "## ----------- New Stuff Ends Here --------- \n",
    "\n",
    "# Rest of the model, again, remains the same \n",
    "\n",
    "x = Conv2D(8, (3, 3))(x)    \n",
    "x = Activation('relu')(x) \n",
    "x = MaxPooling2D(pool_size=(2, 2))(x) \n",
    "x = Flatten()(x) \n",
    "\n",
    "x = Dense(num_classes)(x) \n",
    "\n",
    "output = Activation('softmax')(x) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([inputs], output)\n",
    "model.summary()  # Notice the 'Connected To' in the summary \n",
    "\n",
    "#first 3 are basis of the towers - connected to the input\n",
    "#and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "hist3 = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist3.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input layer is the same as our typical CNN model \n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "\n",
    "## ----------- New Stuff Starts Here --------- \n",
    "\n",
    "# 3x3 conv with 3 output channels (same as input channels)\n",
    "# Necessary that we keep the number of channels the same so that the layers can be added \n",
    "\n",
    "y = Conv2D(3, (3, 3), padding='same')(inputs)\n",
    "\n",
    "# This is the residual connection link. Notice that we are no longer sequential \n",
    "z = keras.layers.add([inputs, y])   # this returns x + y. \n",
    "#basically adding layer consisting of original input and output of previous layer/s \n",
    "\n",
    "\n",
    "## ----------- New Stuff Ends Here --------- \n",
    "\n",
    "# Rest of the model, again, remains the same \n",
    "\n",
    "x = Conv2D(8, (3, 3))(z)    # Notice the 'z'  \n",
    "x = Activation('relu')(x) \n",
    "x = MaxPooling2D(pool_size=(2, 2))(x) \n",
    "x = Flatten()(x) \n",
    "\n",
    "x = Dense(num_classes)(x) \n",
    "\n",
    "output = Activation('softmax')(x) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([inputs], output)\n",
    "model.summary()  # Notice the 'Connected To' in the summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model (to avoid model.fit (=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install h5py --user  # to install h5py module (needed for saving models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py  # to ensure we have this package installed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath=\"checkpoints/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, \n",
    "                             monitor='val_acc', \n",
    "                             verbose=1, \n",
    "                             mode='max')\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)   # produces the same results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Doing basically all the steps \n",
    "##### Defining the same model, with same shapes\n",
    "##### But not fitting it (because training is costly)\n",
    "##### just loading previously saved weights and evaluate (much faster than training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "np.random.seed(1337) \n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model #for functional API\n",
    "from keras.layers import Dense, Activation, Flatten, MaxPooling2D, Dropout, Input\n",
    "from keras.layers import Conv2D #layer that makes our CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # 32 data points trained with model at 1 epoch\n",
    "num_classes = 10 \n",
    "epochs = 5 #how many times NN will see our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data() #already splited\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255 #normalize\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape) #50000 data points, each is 32*32*3 matrix, RGB \n",
    "print(x_train.shape[0], 'train samples') \n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes) #convert labels into binary\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input layer is the same as our typical CNN model \n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "\n",
    "## ----------- New Stuff Starts Here --------- \n",
    "\n",
    "# 3x3 conv with 3 output channels (same as input channels)\n",
    "# Necessary that we keep the number of channels the same so that the layers can be added \n",
    "\n",
    "y = Conv2D(3, (3, 3), padding='same')(inputs)\n",
    "\n",
    "# This is the residual connection link. Notice that we are no longer sequential \n",
    "z = keras.layers.add([inputs, y])   # this returns x + y. \n",
    "#basically adding layer consisting of original input and output of previous layer/s \n",
    "\n",
    "\n",
    "## ----------- New Stuff Ends Here --------- \n",
    "\n",
    "# Rest of the model, again, remains the same \n",
    "\n",
    "x = Conv2D(8, (3, 3))(z)    # Notice the 'z'  \n",
    "x = Activation('relu')(x) \n",
    "x = MaxPooling2D(pool_size=(2, 2))(x) \n",
    "x = Flatten()(x) \n",
    "\n",
    "x = Dense(num_classes)(x) \n",
    "\n",
    "output = Activation('softmax')(x) \n",
    "\n",
    "\n",
    "\n",
    "model = Model([inputs], output)\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just create the model as before and then load weight \n",
    "filepath=\"checkpoints/weights-improvement-05-0.48.hdf5\"\n",
    "model.load_weights(filepath)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)   # produces the same results "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
